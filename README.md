# Class-imbalance-and-distributional-overlap-
This project presents a comprehensive machine learning framework for detecting fraudulent credit card transactions, addressing the critical challenges of class imbalance and class overlap in financial datasets. It begins with importing key libraries for data manipulation, visualization, and modeling, including scikit-learn, imbalanced-learn, and XGBoost. The Credit Card Fraud Detection dataset is utilized, consisting of 31 columns with PCA-transformed features (V1–V28), transaction amount, time, and a binary class label indicating fraud or non-fraud.  Data preprocessing includes exploratory data analysis (EDA) to examine feature distributions, correlations, and imbalances. The analysis confirms that fraud cases represent only 0.17% of transactions, highlighting severe class skew. Visualization techniques such as boxplots, histograms, and correlation heatmaps reveal skewness, outliers, and feature relationships. Outliers in the ‘Amount’ column are removed using the interquartile range (IQR), while RobustScaler is applied to reduce sensitivity to extreme values. Dimensionality reduction techniques including PCA, t-SNE, and TruncatedSVD are employed to visualize class overlap, confirming significant mixing between fraudulent and legitimate transactions.  The framework evaluates multiple ensemble classifiers Random Forest, Balanced Random Forest, AdaBoost, XGBoost, and EasyEnsemble paired with various resampling methods such as SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling/Undersampling, SMOTETomek, and SMOTEENN. Models are trained on resampled data and assessed with metrics including accuracy, precision, recall, F1-score, AUC, MCC, and Youden Index. Hyperparameter tuning via GridSearchCV is conducted to optimize performance, with results systematically stored and compared using evaluation matrices. Comprehensive visualizations, including confusion matrices, ROC curves, learning curves, and overlap plots, provide insights into model effectiveness. The results demonstrate that hybrid approaches particularly combining SMOTE with XGBoost or Balanced Random Forest achieve the highest performance in detecting minority class fraud cases. These models deliver superior F1-scores and AUC values, underscoring the importance of integrating data-level resampling strategies with advanced ensemble learning methods. Overall, the project highlights the effectiveness of carefully designed frameworks that combine robust preprocessing, balanced resampling, and ensemble classifiers. It emphasizes the need for integrated strategies to address extreme class imbalance and overlap in financial datasets, offering valuable insights for improving fraud detection in real-world Big Data applications.
